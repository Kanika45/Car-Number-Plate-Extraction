{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import glob\n",
    "# Imports the Google Cloud client library\n",
    "from google.cloud import vision\n",
    "from google.cloud.vision import types\n",
    "import csv\n",
    "from  cv2 import *\n",
    "import numpy as np\n",
    "import scipy\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "import argparse\n",
    "import os\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files (x86)\\Tesseract-OCR\\tesseract.exe'\n",
    "from PIL import Image, ImageEnhance, ImageFilter\n",
    "import PyPDF2\n",
    "from pdf2image import convert_from_path\n",
    "from __future__ import print_function\n",
    "from wand.image import Image\n",
    "import imutils\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import json\n",
    "import re\n",
    "from passporteye.mrz.image import MRZPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"C:/Users/dsquad/PythonNotebooks/try9.json\"\n",
    "#print(os.environ['GOOGLE_APPLICATION_CREDENTIALS']) \n",
    "# Instantiates a client\n",
    "client = vision.ImageAnnotatorClient()\n",
    "count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(img):\n",
    "    try:\n",
    "        Imagesize=''\n",
    "        img = cv2.imread(img)\n",
    "        h,w,c= img.shape\n",
    "        #print('firststep')\n",
    "        #plt.figure()\n",
    "        # Creating a Named window to display image\n",
    "        #plt.imshow(img)\n",
    "        # Display image\n",
    "        #print(img.shape)\n",
    "        img = cv2.resize(img, (560, 400), interpolation = cv2.INTER_CUBIC)\n",
    "        #print(img.shape)\n",
    "        #plt.imshow(img)\n",
    "\n",
    "        img_gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        #plt.imshow(img_gray)\n",
    "\n",
    "        noise_removal = cv2.bilateralFilter(img_gray, 9, 75, 75)\n",
    "        #plt.imshow(noise_removal)\n",
    "\n",
    "        equal_histogram = cv2.equalizeHist(noise_removal)\n",
    "        #plt.imshow(equal_histogram)\n",
    "\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))\n",
    "        morph_image = cv2.morphologyEx(equal_histogram, cv2.MORPH_OPEN, kernel, iterations = 15)\n",
    "        #plt.imshow(morph_image)\n",
    "\n",
    "        sub_morp_image = cv2.subtract(equal_histogram, morph_image)\n",
    "        #plt.imshow(sub_morp_image)\n",
    "\n",
    "        ret, thresh_image = cv2.threshold(sub_morp_image, 100, 255, cv2.THRESH_OTSU)\n",
    "        #plt.imshow(thresh_image)\n",
    "\n",
    "        canny_image = cv2.Canny(thresh_image, 250, 255)\n",
    "        canny_image = cv2.convertScaleAbs(canny_image)\n",
    "        #plt.imshow(canny_image)\n",
    "\n",
    "        kernel = np.ones((3, 3), np.uint8)\n",
    "        # Creating the kernel for dilation\n",
    "        dilated_image = cv2.dilate(canny_image, kernel, iterations = 1)\n",
    "        #plt.imshow(dilated_image)\n",
    "\n",
    "        new, contours, hierarchy = cv2.findContours(dilated_image, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        contours = sorted(contours, key = cv2.contourArea, reverse = True)[: 10]\n",
    "        # Sort the contours based on area, so that the number plate will be in top 10 contours\n",
    "        screenCnt = None\n",
    "        # loop over our contours\n",
    "        #plt.ion()\n",
    "\n",
    "        for c in contours:\n",
    "        # approximate the contour\n",
    "            peri = cv2.arcLength(c, True)\n",
    "        #print(peri)\n",
    "            approx = cv2.approxPolyDP(c, 0.06 * peri, True)\n",
    "        #print(approx) # Approximating with 6 % error\n",
    "        # if our approximated contour has four points, then\n",
    "        # we can assume that we have found our screen\n",
    "        #print(len(approx))\n",
    "            if len(approx) == 4: # Select the contour with 4 corners\n",
    "                screenCnt = approx\n",
    "        #else :\n",
    "        #print('contours problem')\n",
    "        #Status = 'No Contours detected'\n",
    "            break\n",
    "        final = cv2.drawContours(img, [screenCnt], -1, (0, 255, 0), 3)\n",
    "        #imgplot = plt.imshow(final)\n",
    "        #plt.show(block = False)\n",
    "        #plt.pause(3)\n",
    "        #check = input(\"is image correct?\")\n",
    "        #plt.imshow(final)\n",
    "        mask = np.zeros(img_gray.shape, np.uint8)\n",
    "        new_image = cv2.drawContours(mask, [screenCnt], 0, 255, -1, )\n",
    "        new_image = cv2.bitwise_and(img, img, mask = mask)\n",
    "        # Histogram equal for enhancing the number plate for further processing\n",
    "        y, cr, cb = cv2.split(cv2.cvtColor(new_image, cv2.COLOR_RGB2YCrCb))\n",
    "        # Converting the image to YCrCb model and splitting the 3 channels\n",
    "        y = cv2.equalizeHist(y)\n",
    "        # Applying histogram equalisation\n",
    "        final_image = cv2.cvtColor(cv2.merge([y, cr, cb]), cv2.COLOR_YCrCb2RGB)\n",
    "        #plt.imshow(final_image)\n",
    "        DetectedPlate_byCV2 = pytesseract.image_to_string(final_image)\n",
    "        #cv2.imwrite('./carimages/f/hey.jpg', final_image)\n",
    "        #img = cv2.imread('./carimages/f/hey.jpg')\n",
    "        #imgBlurred = cv2.GaussianBlur(img, (5, 5), 0)\n",
    "        #gray = cv2.cvtColor(imgBlurred, cv2.COLOR_BGR2GRAY)\n",
    "        #ret2, threshold_img = cv2.threshold(gray, 60, 255, cv2.THRESH_BINARY_INV) #+cv2.THRESH_OTSU)\n",
    "        #g = pytesseract.image_to_string(threshold_img)\n",
    "        if len(DetectedPlate_byCV2) > 0 :\n",
    "            Message_byCV2 = 'Plate successfully found by CV2' \n",
    "            Status_byCV2 = 'O'\n",
    "            return Imagesize,Status_byCV2, DetectedPlate_byCV2, Message_byCV2,w,  h\n",
    "        else:\n",
    "            Message_byCV2 = 'No Plate found by CV2' \n",
    "            return Imagesize,Status_byCV2, DetectedPlate_byCV2, Message_byCV2,w, h\n",
    "    except:\n",
    "        Message_byCV2 = 'No Plate found by CV2'\n",
    "        Status_byCV2='N'\n",
    "        DetectedPlate_byCV2 =\"\"\n",
    "        return Imagesize,Status_byCV2, DetectedPlate_byCV2, Message_byCV2, w,h\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./carimages/LicensePlatesOCR4.csv\", \"w\", encoding=\"utf-8\") as LicenseFile:\n",
    "    fieldnames = ['File_Name','Imagewidth','Imageheight','Status_byGoogle','Dectected_Plate_byGoogle','Message_byGoogle','Metadata', 'Status_byCV2','DetectedPlate_byCV2','Message_byCV2']\n",
    "    writer = csv.DictWriter(LicenseFile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for img in glob.glob('./carimages/NewLicensePlates/*.jpg'):\n",
    "        with open(img, 'rb') as image_file:\n",
    "            Imagesize=''\n",
    "            Status_byGoogle ='N'\n",
    "            Message_byGoogle = ''\n",
    "            Metadata= ''\n",
    "            t=''\n",
    "            s=''\n",
    "            w=''\n",
    "            Status_byCV2='N'\n",
    "            DetectedPlate_byCV2 =\"\"\n",
    "            Message_byCV2=''\n",
    "            content = image_file.read()\n",
    "            image = vision.types.Image(content=content)\n",
    "            response = client.document_text_detection(image=image)\n",
    "            texts=(response.text_annotations)\n",
    "            #i = cv2.imread(img)\n",
    "\n",
    "            #print (texts)\n",
    "            if len(texts) > 0 :\n",
    "                strange=texts[0].description\n",
    "                match1 = re.search('[A-Z][A-Z]([\\s\\.-]?)([\\s\\.-]?)([0-9][0-9][0-9])([\\s\\.-]?)([\\s\\.-]?)[A-Z][A-Z]', strange)\n",
    "                match2 = re.search('[0-9][0-9]([0-9]?)([\\s\\.-]?)([\\s\\.-]?)([A-Z][A-Z][A-Z])([\\s\\.-]?)([\\s\\.-]?)[0-9][0-9]', strange)\n",
    "                match3 = re.search('[0-9][0-9][0-9][0-9]([\\s\\.-]?)([\\s\\.-]?)([A-Z][A-Z])([\\s\\.-]?)([\\s\\.-]?)[0-9][0-9]', strange)                \n",
    "                if match1:\n",
    "                    #print ( \"plate found\", match1.group()) \n",
    "                    t=match1.group()\n",
    "                    Status_byGoogle ='O'\n",
    "                    Message_byGoogle= 'Plate successfully found by Google API'\n",
    "                    Metadata= ''\n",
    "                elif match2:\n",
    "                    #print ( \"plate found\", match2.group()) \n",
    "                    t=match2.group()\n",
    "                    Status_byGoogle ='O'\n",
    "                    Message_byGoogle= 'Plate successfully found by Google API'\n",
    "                    Metadata= ''\n",
    "                elif match3:\n",
    "                    #print ( \"plate found\", match2.group()) \n",
    "                    t=match3.group()\n",
    "                    Status_byGoogle ='O'\n",
    "                    Message_byGoogle= 'Plate successfully found by Google API'\n",
    "                    Metadata= ''                    \n",
    "                else:\n",
    "                    Message_byGoogle ='No Plate found by Google API'\n",
    "                    Metadata=  strange\n",
    "            else:\n",
    "                Message_byGoogle ='No Plate found by Google API'\n",
    "            Imagesize,Status_byCV2, DetectedPlate_byCV2, Message_byCV2,  w,h=process(img)\n",
    "            writer.writerow({'File_Name': img, 'Imagewidth':w,'Imageheight' :h ,'Status_byGoogle':Status_byGoogle , 'Dectected_Plate_byGoogle': t, 'Message_byGoogle': Message_byGoogle,'Metadata':Metadata,'Status_byCV2': Status_byCV2,'DetectedPlate_byCV2':DetectedPlate_byCV2,'Message_byCV2':Message_byCV2})  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
